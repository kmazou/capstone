{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Data Wrangling Lab**\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Identify duplicate values in the dataset.\n","\n","-   Remove duplicate values from the dataset.\n","\n","-   Identify missing values in the dataset.\n","\n","-   Impute the missing values in the dataset.\n","\n","-   Normalize data in the dataset.\n"]},{"cell_type":"markdown","metadata":{},"source":["<hr>\n"]},{"cell_type":"markdown","metadata":{},"source":["Import pandas module.\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["Load the dataset into a dataframe.\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Finding duplicates\n"]},{"cell_type":"markdown","metadata":{},"source":["Number of  duplicated rows exist in the dataframe.\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Duplicate Rows: 154\n"]}],"source":["duplicate_rows= df[df.duplicated(keep=\"first\")]\n","num_duplicate_rows=len(duplicate_rows)\n","print(f\"Number of Duplicate Rows: {num_duplicate_rows}\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of duplicate values in the 'Respondent' column: 154\n"]}],"source":["duplicate_count = df.duplicated(subset=[\"Respondent\"]).sum()\n","print(\"Number of duplicate values in the 'Respondent' column:\", duplicate_count)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Removing duplicates\n"]},{"cell_type":"markdown","metadata":{},"source":["Removed the duplicate rows from the dataframe.\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["df=df.drop_duplicates()"]},{"cell_type":"markdown","metadata":{},"source":["Verified if duplicates were actually dropped.\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Duplicates were dropped.\n"]}],"source":["duplicate_rows_df = df[df.duplicated(keep=False)]\n","if df.shape  != duplicate_rows_df.shape:\n","    print(\"Duplicates were dropped.\")\n","else:\n","    print(\"No duplicates were dropped.\")"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of rows after removing duplicate rows: 11398\n"]}],"source":["rows_after_duplicates_removal = df.shape[0]\n","print(\"Number of rows after removing duplicate rows:\", rows_after_duplicates_removal)\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique respondents after removing duplicate rows: 11398\n"]}],"source":["unique_respondents = df['Respondent'].nunique()\n","print(\"Number of unique respondents after removing duplicate rows:\", unique_respondents)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Finding Missing values\n"]},{"cell_type":"markdown","metadata":{},"source":["Found the missing values for all columns.\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Respondent        0\n","MainBranch        0\n","Hobbyist          0\n","OpenSourcer       0\n","OpenSource       81\n","               ... \n","Sexuality       542\n","Ethnicity       675\n","Dependents      140\n","SurveyLength     19\n","SurveyEase       14\n","Length: 85, dtype: int64\n"]}],"source":["missing_values=df.isnull().sum()\n","print(missing_values)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of missing (blank) rows in the 'EdLevel' column after removing duplicate rows: 112\n"]}],"source":["missing_edlevel_rows = df['EdLevel'].isna().sum()\n","print(\"Number of missing (blank) rows in the 'EdLevel' column after removing duplicate rows:\", missing_edlevel_rows)\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of missing (blank) rows in the 'Country' column after removing duplicate rows: 0\n"]}],"source":["missing_country_rows = df['Country'].isna().sum()\n","print(\"Number of missing (blank) rows in the 'Country' column after removing duplicate rows:\", missing_country_rows)\n"]},{"cell_type":"markdown","metadata":{},"source":["Found out the number of  rows that are missing in the column 'WorkLoc'\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of missing values in the 'WorkLoc' column: Respondent        0\n","MainBranch        0\n","Hobbyist          0\n","OpenSourcer       0\n","OpenSource       81\n","               ... \n","Sexuality       542\n","Ethnicity       675\n","Dependents      140\n","SurveyLength     19\n","SurveyEase       14\n","Length: 85, dtype: int64\n"]}],"source":["missing_workloc = df[\"WorkLoc\"].isnull().sum()\n","print(\"Number of missing values in the 'WorkLoc' column:\", missing_values)"]},{"cell_type":"markdown","metadata":{},"source":["## Imputing missing values\n"]},{"cell_type":"markdown","metadata":{},"source":["Found the  value counts for the column WorkLoc.\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Office                                            6806\n","Home                                              3589\n","Other place, such as a coworking space or cafe     971\n","Name: WorkLoc, dtype: int64\n"]}],"source":["workloc_counts = df[\"WorkLoc\"].value_counts()\n","print(workloc_counts)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Majority category under the 'Employment' column: Employed full-time\n"]}],"source":["majority_employment_category = df['Employment'].mode().values[0]\n","print(\"Majority category under the 'Employment' column:\", majority_employment_category)\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Category with the minimum number of rows under the 'UndergradMajor' column: A health science (ex. nursing, pharmacy, radiology)\n"]}],"source":["min_undergrad_major_category = df['UndergradMajor'].value_counts().idxmin()\n","print(\"Category with the minimum number of rows under the 'UndergradMajor' column:\", min_undergrad_major_category)\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2000000.0    138\n","1000000.0    105\n","100000.0      99\n","150000.0      92\n","120000.0      86\n","            ... \n","79183.0        1\n","20475.0        1\n","288732.0       1\n","22056.0        1\n","19880.0        1\n","Name: ConvertedComp, Length: 3515, dtype: int64\n"]}],"source":["ConvertedComp_counts = df[\"ConvertedComp\"].value_counts()\n","print(ConvertedComp_counts)"]},{"cell_type":"markdown","metadata":{},"source":["Identified the value that is most frequent (majority) in the WorkLoc column.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Office is the most frequent in the WorkLoc column (6806)."]},{"cell_type":"markdown","metadata":{},"source":["Imputed (replaced) all the empty rows in the column WorkLoc with the value  identified as majority.\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["df.loc[df[\"WorkLoc\"].isnull(), \"WorkLoc\"] = \"Office\""]},{"cell_type":"markdown","metadata":{},"source":["Verified if imputing was successful.\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of missing values in WorkLoc after imputation: 0\n"]}],"source":["missing_values = df[\"WorkLoc\"].isnull().sum()\n","print(\"Number of missing values in WorkLoc after imputation:\", missing_values)"]},{"cell_type":"markdown","metadata":{},"source":["## Normalizing data\n"]},{"cell_type":"markdown","metadata":{},"source":["There are two columns in the dataset that talk about compensation.\n","\n","One is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n","\n","The other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n","\n","This makes it difficult to compare the total compensation of the developers.\n","\n","In this section I  created a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n","\n","Once this column is ready, it makes comparison of salaries easy.\n"]},{"cell_type":"markdown","metadata":{},"source":["<hr>\n"]},{"cell_type":"markdown","metadata":{},"source":["Listed out the various categories in the column 'CompFreq'\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["6073\n"]}],"source":["yearly_paid = df[df['CompFreq'] == 'Yearly']\n","unique_respondents = yearly_paid['Respondent'].nunique()\n","print(unique_respondents)\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categories in the ComFreq column: ['Yearly' 'Monthly' 'Weekly' nan]\n"]}],"source":["# your code goes here\n","categories = df[\"CompFreq\"].unique()\n","print(\"Categories in the ComFreq column:\", categories)"]},{"cell_type":"markdown","metadata":{},"source":["Created a new column named 'NormalizedAnnualCompensation'.\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def normalize_compensation(row):\n","    if row['CompFreq'] == 'Yearly':\n","        return row['CompTotal']\n","    elif row['CompFreq'] == 'Monthly':\n","        return row['CompTotal'] * 12\n","    elif row['CompFreq'] == 'Weekly':\n","        return row['CompTotal'] * 52\n","    return None  # Handle missing or invalid values\n","\n","df = df.copy()\n","df['NormalizedAnnualCompensation'] = df.apply(lambda row: normalize_compensation(row), axis=1)\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100000.0\n"]}],"source":["median_normalized_compensation = df['NormalizedAnnualCompensation'].median()\n","print(median_normalized_compensation)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Author\n"]},{"cell_type":"markdown","metadata":{},"source":["Karim Ali\n"]}],"metadata":{"kernelspec":{"display_name":"DataScience","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":4}
